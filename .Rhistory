df
df<-read.csv('heat_value_VPM.csv', header=F,sep=',')
df <- df[,apply(df, 2, var, na.rm=TRUE) != 0]
df[df==0] <-NA
BIC <- mclustBIC(df)
plot(BIC)
df
df[df==0] <- 0.000001
df<-read.csv('heat_value_VPM.csv', header=F,sep=',')
df <- df[,apply(df, 2, var, na.rm=TRUE) != 0]
df[df==0] <- 0.000001
BIC <- mclustBIC(df)
plot(BIC)
X
library(mclust)
df<-read.csv('heat_value_VPM.csv', header=F,sep=',')
BIC <- mclustBIC(df,G=1:20)
plot(BIC)
library(mclust)
df<-read.csv('heat_value_VPM.csv', header=F,sep=',')
BIC <- mclustBIC(df,G=1:30)
plot(BIC)
as.matrix(df)
BIC <- mclustBIC(as.matrix(df))
plot(BIC)
BIC <- mclustBIC(t(as.matrix(df)))
plot(BIC)
BIC <- mclustBIC(t(as.matrix(df)),G=1:20)
plot(BIC)
BIC <- mclustBIC(t(as.matrix(df)),G=1:30)
plot(BIC)
BIC <- mclustBIC(as.matrix(df),G=1:30)
plot(BIC)
mydata <- df
wss <- (nrow(mydata)-1)*sum(apply(mydata,2,var))
for (i in 2:15) wss[i] <- sum(kmeans(mydata,
centers=i)$withinss)
plot(1:15, wss, type="b", xlab="Number of Clusters",
ylab="Within groups sum of squares")
library(fpc)
install.packages("fpc")
library(fpc)
pamk.best <- pamk(a)
cat("number of clusters estimated by optimum average silhouette width:", pamk.best$nc, "\n")
plot(pam(d, pamk.best$nc))
asw <- numeric(20)
for (k in 2:20)
asw[[k]] <- pam(a, k) $ silinfo $ avg.width
for (k in 2:20)
asw[[k]] <- pam(a, k) $ silinfo $ avg.width
k.best <- which.max(asw)
cat("silhouette-optimal number of clusters:", k.best, "\n")
install.packages("vegan")
fit <- cascadeKM(scale(a, center = TRUE,  scale = TRUE), 1, 10, iter = 1000)
require(vegan)
fit <- cascadeKM(scale(a, center = TRUE,  scale = TRUE), 1, 10, iter = 1000)
plot(fit, sortg = TRUE, grpmts.plot = TRUE)
calinski.best <- as.numeric(which.max(fit$results[2,]))
cat("Calinski criterion optimal number of clusters:", calinski.best, "\n")
library(fpc)
pamk.best <- pamk(a)
cat("number of clusters estimated by optimum average silhouette width:", pamk.best$nc, "\n")
plot(pamk(d, pamk.best$nc))
plot(pam(a, pamk.best$nc))
plot(pamk(a, pamk.best$nc))
library(fpc)
asw <- numeric(20)
for (k in 2:20)
asw[[k]] <- pam(a, k) $ silinfo $ avg.width
k.best <- which.max(asw)
mclustICL(df)
plot(mclustICL(df))
BIC <- mclustBIC(df,G=1:30)
plot(BIC)
BIC
scale(df)
BIC <- mclustBIC(scale(df))#,G=1:30)
df <- scale(df)
BIC <- mclustBIC(scale(df))#,G=1:30)
df<-read.csv('heat_value_VPM.csv', header=F,sep=',')
df <- scale(df)
BIC <- mclustBIC(scale(df))#,G=1:30)
df
mydata <- na.omit(mydata) # listwise deletion of missing
mydata <- scale(mydata) # standardize variables
df <- scale(df)
BIC <- mclustBIC(df)#,G=1:30)
BIC <- mclustBIC(mydata)#,G=1:30)
library(mclust)
df<-read.csv('heat_value_VPM.csv', header=F,sep=',')
df <- scale(t(df))
BIC <- mclustBIC(df)#,G=1:30)
plot(BIC)
df <- scale(t(df))
BIC <- mclustBIC(t(df))#,G=1:30)
plot(BIC)
library(mclust)
df<-read.csv('heat_value_VPM.csv', header=F,sep=',')
# df <- df[,apply(df, 2, var, na.rm=TRUE) != 0]
# df[df==0] <- 0.000001
# df <- scale(t(df))
BIC <- mclustBIC(df)#,G=1:30)
plot(BIC)
library(pvclust)
mydata <- df
fit <- pvclust(mydata, method.hclust="ward",
method.dist="euclidean")
plot(fit) # dendogram with p values
# add rectangles around groups highly supported by the data
pvrect(fit, alpha=.95)
fit <- pvclust(mydata, method.hclust="ward.D2",
method.dist="euclidean")
plot(fit) # dendogram with p values
# add rectangles around groups highly supported by the data
pvrect(fit, alpha=.95)
fit <- pvclust(mydata, method.hclust="kmeans",
method.dist="euclidean")
fit <- pvclust(mydata, method.hclust="k-means",
method.dist="euclidean")
library(fpc)
pamk.best <- pamk(df)
cat("number of clusters estimated by optimum average silhouette width:", pamk.best$nc, "\n")
plot(pam(a, pamk.best$nc))
library(cluster)
pamk.best <- pamk(df)
cat("number of clusters estimated by optimum average silhouette width:", pamk.best$nc, "\n")
plot(pam(a, pamk.best$nc))
df[df==0] <- NA
pamk.best <- pamk(df)
cat("number of clusters estimated by optimum average silhouette width:", pamk.best$nc, "\n")
plot(pam(a, pamk.best$nc))
df<-read.csv('heat_value_VPM.csv', header=F,sep=',')
df <- scale(df)
pamk.best <- pamk(df)
cat("number of clusters estimated by optimum average silhouette width:", pamk.best$nc, "\n")
plot(pam(a, pamk.best$nc))
df<-read.csv('heat_value_VPM.csv', header=F,sep=',')
df <- scale(t(df))
pamk.best <- pamk(df)
cat("number of clusters estimated by optimum average silhouette width:", pamk.best$nc, "\n")
plot(pam(a, pamk.best$nc))
df<-read.csv('heat_value_VPM.csv', header=F,sep=',')
mydata <- t(df)
fit <- pvclust(mydata, method.hclust="ward",
method.dist="euclidean")
plot(fit) # dendogram with p values
# add rectangles around groups highly supported by the data
pvrect(fit, alpha=.95)
# add rectangles around groups highly supported by the data
pvrect(fit, alpha=.99)
plot(fit)
# add rectangles around groups highly supported by the data
pvrect(fit, alpha=.99)
df<-read.csv('heat_value_VPM.csv', header=F,sep=',')
df <- scale(df)
pamk.best <- pamk(df)
cat("number of clusters estimated by optimum average silhouette width:", pamk.best$nc, "\n")
plot(pam(df, pamk.best$nc))
asw <- numeric(20)
for (k in 2:20)
asw[[k]] <- pam(a, k) $ silinfo $ avg.width
k.best <- which.max(asw)
cat("silhouette-optimal number of clusters:", k.best, "\n")
asw
plot(asw)
df<-read.csv('heat_value_VPM.csv', header=F,sep=',')
asw <- numeric(20)
for (k in 2:20)
asw[[k]] <- pam(a, k) $ silinfo $ avg.width
k.best <- which.max(asw)
cat("silhouette-optimal number of clusters:", k.best, "\n")
setwd("F:/bigneuron/Both_GS_and_auto/shiny_app")
library(mclust)
load('shiny_app/groupsdf.Rdata')
load('shiny_app/subsetdata.Rdata')
setwd("F:/bigneuron/Both_GS_and_auto")
load('shiny_app/groupsdf.Rdata')
load('shiny_app/subsetdata.Rdata')
df <- my_data[groupsdf$group=="Gold_Standard"]
df <- my_data[groupsdf$group=="Gold_Standard",]
library(mclust)
BIC <- mclustBIC(df)#,G=1:30)
plot(BIC)
df
scale(df)
BIC <- mclustBIC(scale(df))#,G=1:30)
plot(BIC)
df <- df[,apply(df, 2, var, na.rm=TRUE) != 0]
# df <- scale(t(df))
BIC <- mclustBIC(df)#,G=1:30)
plot(BIC)
df[df==NA]
df[df==Inf]
df[df==-Inf]
df
df[df==NA] <- 0
df[df==Inf] <- 0
df[df==-Inf] <- 0
# df <- scale(t(df))
BIC <- mclustBIC(df)#,G=1:30)
df
tail(df)
which(df==NA)
which(df==Inf)
which(df==-Inf)
df==NA
df <- my_data[groupsdf$group=="Gold_Standard",]
# df <- scale(t(df))
BIC <- mclustBIC(scale(df))#,G=1:30)
df <- df[,apply(df, 2, var, na.rm=TRUE) != 0]
# df <- scale(t(df))
BIC <- mclustBIC(scale(df))#,G=1:30)
# df <- scale(t(df))
BIC <- mclustBIC(df)#,G=1:30)
df[is.na(df)] <- 0
df <- df[,apply(df, 2, var, na.rm=TRUE) != 0]
# df <- scale(t(df))
BIC <- mclustBIC(df)#,G=1:30)
plot(BIC)
# df <- scale(t(df))
BIC <- mclustBIC(scale(df))#,G=1:30)
plot(BIC)
pcadata <- df
for(i in 1:length(pcadata)){
if(skewness(pcadata[,i]) > 1){
pcadata[,i] <- log10(pcadata[,i])
}
else if(skewness(pcadata[,i]) < (-1)){
pcadata[,i] <- log10(max(pcadata[,i]+1) - pcadata[,i])
}
}
pcadata[is.na(pcadata)]<-0
pcadata[pcadata=='-Inf']<-0
# library(rglwidget)
# library(Cairo)
# library(plyr)
# library(orca)
# library(ggnewscale)
library(moments)
for(i in 1:length(pcadata)){
if(skewness(pcadata[,i]) > 1){
pcadata[,i] <- log10(pcadata[,i])
}
else if(skewness(pcadata[,i]) < (-1)){
pcadata[,i] <- log10(max(pcadata[,i]+1) - pcadata[,i])
}
}
pcadata[is.na(pcadata)]<-0
pcadata[pcadata=='-Inf']<-0
# df <- scale(t(df))
BIC <- mclustBIC(pcadata#,G=1:30)
)
# df <- scale(t(df))
BIC <- mclustBIC(pcadata)
plot(BIC)
Mclust(pcadata)
summary(Mclust(pcadata))
pcadata2 <- pcadata[,c(10,5,6,7,8,19,20,15,14)]
summary(Mclust(pcadata2))
# df <- scale(t(df))
BIC <- mclustBIC(pcadata2)
plot(BIC)
install.packages("cytominer")
library(cytominer)
correlation_threshold(names(pcadata),as.table(pcadata))
correlation_threshold(names(pcadata),tibble::as.tibble(pcadata))
correlation_threshold(names(pcadata),tibble::as_tibble(pcadata))
correlation_threshold(names(pcadata),tibble::as_tibble(pcadata),cutoff=0.95)
correlation_threshold(names(pcadata),tibble::as_tibble(pcadata),cutoff=0.8)
correlation_threshold(names(pcadata),tibble::as_tibble(pcadata),cutoff=0.7)
correlation_threshold(names(pcadata),tibble::as_tibble(pcadata),cutoff=0.5)
pcadata3[,correlation_threshold(names(pcadata),tibble::as_tibble(pcadata),cutoff=0.5)]
pcadata3<-pcadata[,correlation_threshold(names(pcadata),tibble::as_tibble(pcadata),cutoff=0.5)]
# df <- scale(t(df))
BIC <- mclustBIC(pcadata3)
plot(BIC)
pcadata3<-pcadata[,correlation_threshold(names(pcadata),tibble::as_tibble(pcadata),cutoff=0.4)]
# df <- scale(t(df))
BIC <- mclustBIC(pcadata3)
plot(BIC)
pcadata3<-pcadata[,correlation_threshold(names(pcadata),tibble::as_tibble(pcadata),cutoff=0.7)]
# df <- scale(t(df))
BIC <- mclustBIC(pcadata3)
plot(BIC)
pcadata3<-pcadata[,correlation_threshold(names(pcadata),tibble::as_tibble(pcadata),cutoff=0.8)]
# df <- scale(t(df))
BIC <- mclustBIC(pcadata3)
plot(BIC)
pcadata3<-pcadata[,correlation_threshold(names(pcadata),tibble::as_tibble(pcadata),cutoff=0.9)]
# df <- scale(t(df))
BIC <- mclustBIC(pcadata3)
plot(BIC)
pcadata3<-pcadata[,correlation_threshold(names(pcadata),tibble::as_tibble(pcadata),cutoff=0.6)]
# df <- scale(t(df))
BIC <- mclustBIC(scale(pcadata3))
plot(BIC)
pcadata3<-pcadata[,correlation_threshold(names(pcadata),tibble::as_tibble(pcadata),cutoff=0.65)]
# df <- scale(t(df))
BIC <- mclustBIC(scale(pcadata3))
plot(BIC)
data <- my_data
data[is.na(data)] <- 0
data <- data[,apply(data, 2, var, na.rm=TRUE) != 0]
pcadata<- data
for(i in 1:length(pcadata)){
if(skewness(pcadata[,i]) > 1){
pcadata[,i] <- log10(pcadata[,i])
}
else if(skewness(pcadata[,i]) < (-1)){
pcadata[,i] <- log10(max(pcadata[,i]+1) - pcadata[,i])
}
}
pcadata[is.na(pcadata)]<-0
pcadata[pcadata=='-Inf']<-0
pcadata4<-pcadata[,correlation_threshold(names(pcadata),tibble::as_tibble(pcadata),cutoff=0.9)]
pcadata4<-pcadata[,correlation_threshold(names(pcadata),tibble::as_tibble(pcadata),cutoff=0.65)]
# df <- scale(t(df))
BIC <- mclustBIC(scale(pcadata4))
plot(BIC)
runApp('shiny_app')
mdist <- read.csv("TMD_dists.csv",header=F)
colnames(mdist) <- as.character(unlist(mdist[1,]))
mdist = mdist[-1, ]
rownames(mdist) <- as.character(unlist(mdist[,1]))
mdist = mdist[,-1]
metadata <- read.csv("metadatags.csv")
colrows <- data.frame(ids = colnames(mdist))
colrows <- merge(colrows,metadata, by="ids",sort=F)
idrnames <- rownames(mdist)
idcnames <- colnames(mdist)
labcols <- idcnames
labrows <- idrnames
heatmaply(mdist,
dist_method = "euclidean", hclust_method ="complete",
labCol=labcols,
labRow=labrows,
column_text_angle = 60,
fontsize_row = 5,
fontsize_col = 5)
dend_expend(mdist)
best_clust <- dend_expend(mdist)
best_clust$performance
best_clust$performance[which(max(best_clust$performance$optim))]
best_clust$performance[which(best_clust$performance$optim==max(best_clust$performance$optim))]
best_clust$performance[which(best_clust$performance$optim==max(best_clust$performance$optim)),]
best_clust$performance[,which(best_clust$performance$optim==max(best_clust$performance$optim))]
max(best_clust$performance$optim))
max(best_clust$performance$optim)
max(best_clust$performance
)
best_clust$performance$optim
max(best_clust$performance$optim,na.rm=T)
which9(max(best_clust$performance$optim,na.rm=T))
which(max(best_clust$performance$optim,na.rm=T))
which(best_clust$performance$optim==max(best_clust$performance$optim,na.rm=T))
best_clust$performance[which(best_clust$performance$optim==max(best_clust$performance$optim,na.rm=T)),]
hclust(mdist)
mdist
hclust(as.dist(mdist))
as.dist(mdist)
library("WeightedCluster")
library("WeightedCluster")
hc <- hclust(as.dist(mdist))
hcRange <- as.clustrange(hc, diss=as.dist(mdist), ncluster=6)
summary(hcRange)
plot(hcRange, stat = c("ASWw", "HG", "PBC"), lwd = 2)
hc <- hclust(as.dist(mdist,method = "manhattan"))
hc <- hclust(as.dist(mdist))
hcRange <- as.clustrange(hc, diss=as.dist(mdist), ncluster=6)
summary(hcRange)
plot(hcRange, stat = c("ASWw", "HG", "PBC"), lwd = 2)
runApp('shiny_app')
summary(hcRange)
# library("WeightedCluster")
# hc <- hclust(as.dist(mdist))
# hcRange <- as.clustrange(hc, diss=as.dist(mdist), ncluster=6)
# summary(hcRange)
plot(hcRange, stat=c("ASWw", "HG", "PBC", "HC"), norm="zscore", lwd = 2)
runApp('shiny_app')
hcRange <- as.clustrange(hc, diss=as.dist(mdist), ncluster=20)
summary(hcRange)
plot(hcRange, stat=c("ASWw", "HG", "PBC", "HC"), norm="zscore", lwd = 2)
runApp('shiny_app')
p <- heatmaply(mdist,
k_col = 11,
k_row = 11,
dist_method = "euclidean", hclust_method ="complete",
# dist_method = "manhattan", hclust_method ="complete",
labCol=labcols,
labRow=labrows,
column_text_angle = 60,
fontsize_row = 5,
fontsize_col = 5)
p
filename = function(){paste('PL_matrix', '.pdf', sep = '')},
ggsave('PL_matrix.pdf',width=7,height=7,p)
print(p)
heatmap(mdist,
k_col = 11,
k_row = 11,
dist_method = "euclidean", hclust_method ="complete",
# dist_method = "manhattan", hclust_method ="complete",
labCol=labcols,
labRow=labrows,
column_text_angle = 60,
fontsize_row = 5,
fontsize_col = 5)
heatmap(as.matrix(mdist),
k_col = 11,
k_row = 11,
dist_method = "euclidean", hclust_method ="complete",
# dist_method = "manhattan", hclust_method ="complete",
labCol=labcols,
labRow=labrows,
column_text_angle = 60,
fontsize_row = 5,
fontsize_col = 5)
p <- heatmaply(mdist,
k_col = 11,
k_row = 11,
dist_method = "euclidean", hclust_method ="complete",
# dist_method = "manhattan", hclust_method ="complete",
labCol=labcols,
labRow=labrows,
column_text_angle = 60,
fontsize_row = 5,
fontsize_col = 5,)
)
p <- heatmaply(mdist,
k_col = 11,
k_row = 11,
dist_method = "euclidean", hclust_method ="complete",
# dist_method = "manhattan", hclust_method ="complete",
labCol=labcols,
labRow=labrows,
column_text_angle = 60,
fontsize_row = 5,
fontsize_col = 5,file='PL_matrix.pdf')
install.packages('orca')
p <- heatmaply(mdist,
k_col = 11,
k_row = 11,
dist_method = "euclidean", hclust_method ="complete",
# dist_method = "manhattan", hclust_method ="complete",
labCol=labcols,
labRow=labrows,
column_text_angle = 60,
fontsize_row = 5,
fontsize_col = 5,file='PL_matrix.pdf')
library(orca)
p <- heatmaply(mdist,
k_col = 11,
k_row = 11,
dist_method = "euclidean", hclust_method ="complete",
# dist_method = "manhattan", hclust_method ="complete",
labCol=labcols,
labRow=labrows,
column_text_angle = 60,
fontsize_row = 5,
fontsize_col = 5,file='PL_matrix.pdf')
p <- heatmaply(mdist,
k_col = 11,
k_row = 11,
dist_method = "euclidean", hclust_method ="complete",
# dist_method = "manhattan", hclust_method ="complete",
labCol=labcols,
labRow=labrows,
column_text_angle = 60,
fontsize_row = 5,
fontsize_col = 5,file='PL_matrix.pdf')
library(plotly)
p <- heatmaply(mdist,
k_col = 11,
k_row = 11,
dist_method = "euclidean", hclust_method ="complete",
# dist_method = "manhattan", hclust_method ="complete",
labCol=labcols,
labRow=labrows,
column_text_angle = 60,
fontsize_row = 5,
fontsize_col = 5,file='PL_matrix.pdf')
library(heatmaply)
p <- heatmaply(mdist,
k_col = 11,
k_row = 11,
dist_method = "euclidean", hclust_method ="complete",
# dist_method = "manhattan", hclust_method ="complete",
labCol=labcols,
labRow=labrows,
column_text_angle = 60,
fontsize_row = 5,
fontsize_col = 5,file='PL_matrix.pdf')
p <- heatmaply(mdist,
k_col = 11,
k_row = 11,
dist_method = "euclidean", hclust_method ="complete",
# dist_method = "manhattan", hclust_method ="complete",
labCol=labcols,
labRow=labrows,
column_text_angle = 60,
fontsize_row = 5,
fontsize_col = 5,file='PL_matrix.pdf')
p <- heatmaply(mdist,
k_col = 11,
k_row = 11,
dist_method = "euclidean", hclust_method ="complete",
# dist_method = "manhattan", hclust_method ="complete",
labCol=labcols,
labRow=labrows,
column_text_angle = 60,
fontsize_row = 5,
fontsize_col = 5,file='PL_matrix.pdf')
